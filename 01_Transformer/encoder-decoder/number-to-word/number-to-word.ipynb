{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from num2words import num2words\n",
    "\n",
    "def create_small_dataset():\n",
    "    numbers = list(range(0, 100))\n",
    "    data = [(str(n), num2words(n)) for n in numbers]\n",
    "    df = pd.DataFrame(data, columns=['num', 'word'])\n",
    "    return df\n",
    "\n",
    "small_dataset = create_small_dataset()\n",
    "train_df = small_dataset.sample(frac=1, random_state=42)\n",
    "val_df = train_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(start=0, end=1000, train_size=0.8):\n",
    "   numbers = list(range(start, end))\n",
    "   data = [(str(n), num2words(n)) for n in numbers]\n",
    "   df = pd.DataFrame(data, columns=['num', 'word'])\n",
    "   \n",
    "   train_df = df.sample(frac=train_size, random_state=42)\n",
    "   test_df = df.drop(train_df.index)\n",
    "   \n",
    "   return train_df, test_df\n",
    "\n",
    "train_df, val_df = create_dataset(0, 1000, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 800)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_df), len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>521</td>\n",
       "      <td>five hundred and twenty-one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>737</td>\n",
       "      <td>seven hundred and thirty-seven</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>740</td>\n",
       "      <td>seven hundred and forty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>660</td>\n",
       "      <td>six hundred and sixty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>411</td>\n",
       "      <td>four hundred and eleven</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     num                            word\n",
       "521  521     five hundred and twenty-one\n",
       "737  737  seven hundred and thirty-seven\n",
       "740  740         seven hundred and forty\n",
       "660  660           six hundred and sixty\n",
       "411  411         four hundred and eleven"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(78) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input_format: \n",
      "  model_prefix: num_to_words\n",
      "  model_type: BPE\n",
      "  vocab_size: 200\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 1\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  pretokenization_delimiter: \n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  user_defined_symbols: <PAD>\n",
      "  user_defined_symbols: <BOS>\n",
      "  user_defined_symbols: <EOS>\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  seed_sentencepieces_file: \n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "  enable_differential_privacy: 0\n",
      "  differential_privacy_noise_level: 0\n",
      "  differential_privacy_clipping_threshold: 0\n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(409) LOG(INFO) Loaded all 800 sentences\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <PAD>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <BOS>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <EOS>\n",
      "trainer_interface.cc(430) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(539) LOG(INFO) all chars count=20504\n",
      "trainer_interface.cc(560) LOG(INFO) Alphabet size=21\n",
      "trainer_interface.cc(561) LOG(INFO) Final character coverage=1\n",
      "trainer_interface.cc(592) LOG(INFO) Done! preprocessed 800 sentences.\n",
      "trainer_interface.cc(598) LOG(INFO) Tokenizing input sentences with whitespace: 800\n",
      "trainer_interface.cc(609) LOG(INFO) Done! 102\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1442 min_freq=1\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=238 size=20 all=108 active=87 piece=ei\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=90 size=40 all=130 active=109 piece=▁fif\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=64 size=60 all=118 active=97 piece=eight\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=80 all=114 active=93 piece=▁thirteen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=0 size=100 all=98 active=77 piece=le\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=0 min_freq=0\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=0 size=120 all=78 active=57 piece=and\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=0 size=140 all=58 active=37 piece=▁ei\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=0 size=160 all=38 active=17 piece=ninet\n",
      "trainer_interface.cc(687) LOG(INFO) Saving model: num_to_words.model\n",
      "trainer_interface.cc(699) LOG(INFO) Saving vocabs: num_to_words.vocab\n"
     ]
    }
   ],
   "source": [
    "import sentencepiece as spm\n",
    "import io\n",
    "text_data = \"\\n\".join(train_df['word'])\n",
    "text_stream = io.StringIO(text_data)\n",
    "\n",
    "spm.SentencePieceTrainer.train(\n",
    "    sentence_iterator=text_stream,  # Use in-memory text\n",
    "    model_prefix='num_to_words',    # Model output prefix\n",
    "    vocab_size=200,                   # Adjust vocabulary size based on data\n",
    "    model_type='bpe',                 # Choose 'bpe', 'unigram', etc.\n",
    "    character_coverage=1.0,            # Cover all characters in the dataset\n",
    "    user_defined_symbols=['<PAD>', '<BOS>', '<EOS>']  # Add special tokens\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentencepiece as spm\n",
    "import torch\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "\n",
    "def tokenize_word_column(df_column):\n",
    "    sp = spm.SentencePieceProcessor(model_file='num_to_words.model')\n",
    "\n",
    "    bos_token_id = 4  # <BOS>\n",
    "    eos_token_id = 5  # <EOS>\n",
    "    pad_token_id = 3  # <PAD>\n",
    "\n",
    "    tokenized_words = df_column.apply(lambda x: [bos_token_id] + sp.encode(x, out_type=int) + [eos_token_id])\n",
    "\n",
    "    max_length = tokenized_words.apply(len).max()\n",
    "\n",
    "    padded_tokens = tokenized_words.apply(lambda x: x + [pad_token_id] * (max_length - len(x)))\n",
    "\n",
    "    tensor_data = torch.tensor(padded_tokens.tolist(), dtype=torch.long)\n",
    "\n",
    "    return tensor_data\n",
    "\n",
    "\n",
    "\n",
    "BOS_TOKEN_ID = 10  # Ensure same ID for both input and output\n",
    "EOS_TOKEN_ID = 11\n",
    "PAD_TOKEN_ID = 12\n",
    "\n",
    "def tokenize_number_column(df_column):\n",
    "    tokenized_sequences = [\n",
    "        [BOS_TOKEN_ID] + [int(d) for d in str(num)] + [EOS_TOKEN_ID] for num in df_column\n",
    "    ]\n",
    "\n",
    "    # Ensure consistent padding length across input and target\n",
    "    max_length = max(len(seq) for seq in tokenized_sequences)\n",
    "    \n",
    "    padded_sequences = [\n",
    "        seq + [PAD_TOKEN_ID] * (max_length - len(seq)) for seq in tokenized_sequences\n",
    "    ]\n",
    "\n",
    "    tensor_sequences = torch.tensor(padded_sequences, dtype=torch.long)\n",
    "\n",
    "    return tensor_sequences\n",
    "\n",
    "def decode_number_sequence(sequence):\n",
    "   seq_list = sequence.tolist()\n",
    "   tokens = [\n",
    "       '<BOS>' if x == BOS_TOKEN_ID else\n",
    "       '<EOS>' if x == EOS_TOKEN_ID else\n",
    "       '<PAD>' if x == PAD_TOKEN_ID else\n",
    "       str(x) \n",
    "       for x in seq_list\n",
    "   ]\n",
    "   return \"\".join(tokens)\n",
    "\n",
    "tokenized_words = tokenize_word_column(train_df['word'])\n",
    "tokenized_tensor = tokenize_number_column(train_df['num'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class NumberWordDataset(Dataset):\n",
    "    def __init__(self, input_tensor, target_tensor, pad_token_id=3):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_tensor (torch.Tensor): Tokenized numbers (input sequences).\n",
    "            target_tensor (torch.Tensor): Tokenized words (output sequences).\n",
    "            pad_token_id (int): The ID used for padding.\n",
    "        \"\"\"\n",
    "        self.input_tensor = input_tensor\n",
    "        self.target_tensor = target_tensor\n",
    "        self.pad_token_id = pad_token_id\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_tensor)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_seq = self.input_tensor[idx]\n",
    "        target_seq = self.target_tensor[idx]\n",
    "\n",
    "        # Create attention masks (1 = actual token, 0 = padding)\n",
    "        input_mask = (input_seq != self.pad_token_id).long()\n",
    "        target_mask = (target_seq != self.pad_token_id).long()\n",
    "\n",
    "        return {\n",
    "            'input_seq': input_seq,\n",
    "            'target_seq': target_seq,\n",
    "            'input_mask': input_mask.bool(),  # Convert to boolean\n",
    "            'target_mask': target_mask.bool() \n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataset from tokenized data\n",
    "dataset = NumberWordDataset(tokenized_tensor, tokenized_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoded Input: <BOS>486<EOS>\n",
      "Input: tensor([10,  4,  8,  6, 11])\n",
      "Input Mask: tensor([True, True, True, True, True])\n",
      "Decoded Target: <BOS> four hundred and eighty-six<EOS>\n",
      "Target: tensor([  4,  43,  12,  14,  54, 190,  66,   5])\n",
      "Target Mask: tensor([True, True, True, True, True, True, True, True])\n"
     ]
    }
   ],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "sp = spm.SentencePieceProcessor(model_file='num_to_words.model')\n",
    "\n",
    "# Example: Iterate through the DataLoader\n",
    "for batch in dataloader:\n",
    "    input_seq = batch['input_seq']\n",
    "    target_seq = batch['target_seq']\n",
    "    input_mask = batch['input_mask']\n",
    "    target_mask = batch['target_mask']\n",
    "\n",
    "    decoded_input = decode_number_sequence(input_seq[0])\n",
    "    print(\"Decoded Input:\", decoded_input)\n",
    "    print(\"Input:\", input_seq[0])\n",
    "    print(\"Input Mask:\", input_mask[0])\n",
    "    decoded_target = sp.decode_ids(target_seq[0].tolist())\n",
    "    print(\"Decoded Target:\", decoded_target)\n",
    "    print(\"Target:\", target_seq[0])\n",
    "    print(\"Target Mask:\", target_mask[0])\n",
    "\n",
    "    break  # Just show the first batch for testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, input_vocab_size, target_vocab_size, embed_dim=64, num_heads=4, num_layers=3):\n",
    "        super().__init__()\n",
    "        self.encoder_embedding = nn.Embedding(input_vocab_size, embed_dim)\n",
    "        self.decoder_embedding = nn.Embedding(target_vocab_size, embed_dim)\n",
    "        self.transformer = nn.Transformer(d_model=embed_dim, nhead=num_heads, num_encoder_layers=num_layers, num_decoder_layers=num_layers)\n",
    "        self.fc_out = nn.Linear(embed_dim, target_vocab_size)\n",
    "\n",
    "    def forward(self, src, tgt, src_mask, tgt_mask):\n",
    "        src_emb = self.encoder_embedding(src).permute(1, 0, 2)\n",
    "        tgt_emb = self.decoder_embedding(tgt).permute(1, 0, 2)\n",
    "        output = self.transformer(src_emb, tgt_emb, tgt_mask=self.generate_square_subsequent_mask(tgt.size(1)))\n",
    "        return self.fc_out(output.permute(1, 0, 2))\n",
    "\n",
    "    def generate_square_subsequent_mask(self, sz):\n",
    "        mask = torch.triu(torch.ones(sz, sz), diagonal=1).bool()\n",
    "        return mask.to(next(self.parameters()).device)\n",
    "       \n",
    "\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, input_vocab_size, target_vocab_size, d_model=512, nhead=8, num_layers=6, \n",
    "                 d_ff=2048, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.encoder_embedding = nn.Embedding(input_vocab_size, d_model)\n",
    "        self.decoder_embedding = nn.Embedding(target_vocab_size, d_model)\n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
    "        self.pos_decoder = PositionalEncoding(d_model, dropout)\n",
    "        \n",
    "        self.transformer = nn.Transformer(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            num_encoder_layers=num_layers,\n",
    "            num_decoder_layers=num_layers,\n",
    "            dim_feedforward=d_ff,\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.fc_out = nn.Linear(d_model, target_vocab_size)\n",
    "\n",
    "    def forward(self, src, tgt, src_mask, tgt_mask):\n",
    "        src_emb = self.pos_encoder(self.encoder_embedding(src))\n",
    "        tgt_emb = self.pos_decoder(self.decoder_embedding(tgt))\n",
    "        output = self.transformer(src_emb, tgt_emb, tgt_mask=self.generate_square_subsequent_mask(tgt.size(1)))\n",
    "        return self.fc_out(output)\n",
    "\n",
    "    def generate_square_subsequent_mask(self, sz):\n",
    "        mask = torch.triu(torch.ones(sz, sz), diagonal=1).bool()\n",
    "        return mask.to(next(self.parameters()).device)\n",
    "        \n",
    "class PositionalEncoding(nn.Module):\n",
    "   def __init__(self, d_model, dropout=0.1, max_len=100):\n",
    "       super().__init__()\n",
    "       self.dropout = nn.Dropout(p=dropout)\n",
    "       position = torch.arange(max_len).unsqueeze(1)\n",
    "       div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "       pe = torch.zeros(max_len, d_model)\n",
    "       pe[:, 0::2] = torch.sin(position * div_term)\n",
    "       pe[:, 1::2] = torch.cos(position * div_term)\n",
    "       self.register_buffer('pe', pe)\n",
    "\n",
    "   def forward(self, x):\n",
    "       x = x + self.pe[:x.size(1)]\n",
    "       return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloader, num_epochs=20, learning_rate=1e-5, pad_token_id=3):\n",
    "    device = torch.device(\"cpu\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "    torch.set_default_dtype(torch.float32)  # Use float32 for stability\n",
    "    model.to(device).to(torch.float32)\n",
    "\n",
    "    max_grad_norm = 1.0\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=pad_token_id)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "\n",
    "        for batch in dataloader:\n",
    "            src = batch['input_seq'].to(device)\n",
    "            tgt = batch['target_seq'].to(device)\n",
    "\n",
    "            src_mask = batch['input_mask'].to(device)\n",
    "            tgt_mask = batch['target_mask'].to(device)\n",
    "\n",
    "            # Convert mask to correct type and shape\n",
    "            src_mask = ~src_mask[:, :src.shape[1]].bool().to(device)\n",
    "            tgt_mask = ~tgt_mask[:, :tgt.shape[1]].bool().to(device)\n",
    "\n",
    "            # Ensure tgt_input matches expected length\n",
    "            tgt_input = tgt[:, :-1]  # Remove last token to match expected shape\n",
    "            tgt_output = tgt[:, 1:]  # Shift target sequence for teacher forcing\n",
    "\n",
    "            tgt_input = tgt_input.to(device)\n",
    "            tgt_output = tgt_output.to(device)\n",
    "\n",
    "\n",
    "            # Ensure the target mask shape matches the new target input shape\n",
    "            tgt_mask = tgt_mask[:, :-1]  # Adjust mask length to match tgt_input\n",
    "\n",
    "\n",
    "            # Forward pass\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output = model(src, tgt_input, src_mask, tgt_mask)\n",
    "\n",
    "            # Compute loss\n",
    "            output = output.reshape(-1, output.shape[-1])\n",
    "            tgt_output = tgt_output.reshape(-1)\n",
    "\n",
    "            loss = criterion(output, tgt_output)\n",
    "            loss.backward()\n",
    "\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            # Check for NaN loss\n",
    "            if torch.isnan(loss):\n",
    "                print(f\"NaN loss detected in batch! Skipping batch.\")\n",
    "                continue\n",
    "\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {epoch_loss / len(dataloader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloader, num_epochs=20, learning_rate=1e-4, pad_token_id=3):\n",
    "    # Add initialization\n",
    "    def init_weights(m):\n",
    "        if isinstance(m, (nn.Linear, nn.Embedding)):\n",
    "            torch.nn.init.xavier_uniform_(m.weight)\n",
    "            if hasattr(m, 'bias') and m.bias is not None:\n",
    "                torch.nn.init.zeros_(m.bias)\n",
    "    \n",
    "    model.apply(init_weights)\n",
    "    \n",
    "    if torch.backends.mps.is_available():\n",
    "        device = torch.device(\"cpu\")\n",
    "        torch.backends.mps.enable_fallback_to_cpu = True\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "    \n",
    "    torch.set_default_dtype(torch.float32)\n",
    "    model = model.to(device).to(torch.float32)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=pad_token_id)\n",
    "    \n",
    "    # Training stability parameters\n",
    "    warmup_batches = 3\n",
    "    accumulation_steps = 4  # Only during warmup\n",
    "    max_grad_norm = 0.5\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        \n",
    "        for batch_idx, batch in enumerate(dataloader):\n",
    "            try:\n",
    "                # Move data to device\n",
    "                src = batch['input_seq'].to(device)\n",
    "                tgt = batch['target_seq'].to(device)\n",
    "                src_mask = batch['input_mask'].to(device)\n",
    "                tgt_mask = batch['target_mask'].to(device)\n",
    "                                \n",
    "                # Convert mask to correct type and shape\n",
    "                src_mask = ~src_mask[:, :src.shape[1]].bool().to(device)\n",
    "                tgt_mask = ~tgt_mask[:, :tgt.shape[1]].bool().to(device)\n",
    "                \n",
    "                # Prepare target sequences\n",
    "                tgt_input = tgt[:, :-1].to(device)\n",
    "                tgt_output = tgt[:, 1:].to(device)\n",
    "                tgt_mask = tgt_mask[:, :-1]\n",
    "                \n",
    "                # Forward pass\n",
    "                output = model(src, tgt_input, src_mask, tgt_mask)\n",
    "                \n",
    "                # Check for NaN in output\n",
    "                if torch.isnan(output).any():\n",
    "                    print(\"NaN detected in output before loss!\")\n",
    "                    continue\n",
    "                \n",
    "                # Reshape for loss calculation\n",
    "                output = output.reshape(-1, output.shape[-1])\n",
    "                tgt_output = tgt_output.reshape(-1)\n",
    "                \n",
    "                # Calculate loss\n",
    "                loss = criterion(output, tgt_output)\n",
    "                \n",
    "                # Check for NaN loss\n",
    "                if torch.isnan(loss):\n",
    "                    print(f\"NaN loss detected in batch {batch_idx}!\")\n",
    "                    print(f\"Output stats - min: {output.min()}, max: {output.max()}, mean: {output.mean()}\")\n",
    "                    print(f\"Target stats - min: {tgt_output.min()}, max: {tgt_output.max()}\")\n",
    "                    continue\n",
    "                \n",
    "                # Scale loss during warmup\n",
    "                if epoch == 0 and batch_idx < warmup_batches:\n",
    "                    loss = loss / accumulation_steps\n",
    "                \n",
    "                # Backward pass\n",
    "                loss.backward()\n",
    "                \n",
    "                # Gradient clipping\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=max_grad_norm)\n",
    "                \n",
    "                # Check gradients\n",
    "                for name, param in model.named_parameters():\n",
    "                    if param.grad is not None and torch.isnan(param.grad).any():\n",
    "                        print(f\"NaN gradient detected in {name}\")\n",
    "                        continue\n",
    "                \n",
    "                # Optimizer step\n",
    "                if epoch > 0 or batch_idx >= warmup_batches or (batch_idx + 1) % accumulation_steps == 0:\n",
    "                    optimizer.step()\n",
    "                    optimizer.zero_grad(set_to_none=True)\n",
    "                \n",
    "                epoch_loss += loss.item()\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error in batch {batch_idx}: {str(e)}\")\n",
    "                continue\n",
    "        \n",
    "        avg_epoch_loss = epoch_loss / len(dataloader)\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {avg_epoch_loss:.4f}\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 3.0667\n",
      "Epoch 2/20, Loss: 1.9947\n",
      "Epoch 3/20, Loss: 1.5522\n",
      "Epoch 4/20, Loss: 1.4500\n",
      "Epoch 5/20, Loss: 1.4155\n",
      "Epoch 6/20, Loss: 1.3992\n",
      "Epoch 7/20, Loss: 1.3710\n",
      "Epoch 8/20, Loss: 1.3406\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 13\u001b[0m\n\u001b[1;32m      7\u001b[0m transformer_model \u001b[38;5;241m=\u001b[39m TransformerModel(\n\u001b[1;32m      8\u001b[0m     input_vocab_size\u001b[38;5;241m=\u001b[39minput_vocab_size,\n\u001b[1;32m      9\u001b[0m     target_vocab_size\u001b[38;5;241m=\u001b[39mtarget_vocab_size\n\u001b[1;32m     10\u001b[0m )\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransformer_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[41], line 51\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, dataloader, num_epochs, learning_rate, pad_token_id)\u001b[0m\n\u001b[1;32m     48\u001b[0m tgt_mask \u001b[38;5;241m=\u001b[39m tgt_mask[:, :\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# Check for NaN in output\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misnan(output)\u001b[38;5;241m.\u001b[39many():\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/mps-torch/lib/python3.9/site-packages/torch/nn/modules/module.py:1740\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1739\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1740\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/mps-torch/lib/python3.9/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1748\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1750\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1753\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1754\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[14], line 45\u001b[0m, in \u001b[0;36mTransformerModel.forward\u001b[0;34m(self, src, tgt, src_mask, tgt_mask)\u001b[0m\n\u001b[1;32m     43\u001b[0m src_emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_encoder(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder_embedding(src))\n\u001b[1;32m     44\u001b[0m tgt_emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_decoder(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder_embedding(tgt))\n\u001b[0;32m---> 45\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc_emb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_emb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_square_subsequent_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtgt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc_out(output)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/mps-torch/lib/python3.9/site-packages/torch/nn/modules/module.py:1740\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1739\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1740\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/mps-torch/lib/python3.9/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1748\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1750\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1753\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1754\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/mps-torch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:268\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, src, tgt, src_mask, tgt_mask, memory_mask, src_key_padding_mask, tgt_key_padding_mask, memory_key_padding_mask, src_is_causal, tgt_is_causal, memory_is_causal)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m src\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md_model \u001b[38;5;129;01mor\u001b[39;00m tgt\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md_model:\n\u001b[1;32m    264\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    265\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe feature number of src and tgt must be equal to d_model\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    266\u001b[0m     )\n\u001b[0;32m--> 268\u001b[0m memory \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc_is_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    274\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(\n\u001b[1;32m    275\u001b[0m     tgt,\n\u001b[1;32m    276\u001b[0m     memory,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    282\u001b[0m     memory_is_causal\u001b[38;5;241m=\u001b[39mmemory_is_causal,\n\u001b[1;32m    283\u001b[0m )\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/mps-torch/lib/python3.9/site-packages/torch/nn/modules/module.py:1740\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1739\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1740\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/mps-torch/lib/python3.9/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1748\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1750\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1753\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1754\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/mps-torch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:507\u001b[0m, in \u001b[0;36mTransformerEncoder.forward\u001b[0;34m(self, src, mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    504\u001b[0m is_causal \u001b[38;5;241m=\u001b[39m _detect_is_causal_mask(mask, is_causal, seq_len)\n\u001b[1;32m    506\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mod \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m--> 507\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmod\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    508\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    509\u001b[0m \u001b[43m        \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    510\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    511\u001b[0m \u001b[43m        \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc_key_padding_mask_for_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    512\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    514\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_nested:\n\u001b[1;32m    515\u001b[0m     output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mto_padded_tensor(\u001b[38;5;241m0.0\u001b[39m, src\u001b[38;5;241m.\u001b[39msize())\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/mps-torch/lib/python3.9/site-packages/torch/nn/modules/module.py:1740\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1739\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1740\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/mps-torch/lib/python3.9/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1748\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1750\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1753\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1754\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/mps-torch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:900\u001b[0m, in \u001b[0;36mTransformerEncoderLayer.forward\u001b[0;34m(self, src, src_mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    896\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ff_block(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x))\n\u001b[1;32m    897\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    898\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1(\n\u001b[1;32m    899\u001b[0m         x\n\u001b[0;32m--> 900\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sa_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    901\u001b[0m     )\n\u001b[1;32m    902\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ff_block(x))\n\u001b[1;32m    904\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/mps-torch/lib/python3.9/site-packages/torch/nn/modules/transformer.py:914\u001b[0m, in \u001b[0;36mTransformerEncoderLayer._sa_block\u001b[0;34m(self, x, attn_mask, key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    907\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_sa_block\u001b[39m(\n\u001b[1;32m    908\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    909\u001b[0m     x: Tensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    912\u001b[0m     is_causal: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    913\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 914\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    915\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    922\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    923\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout1(x)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/mps-torch/lib/python3.9/site-packages/torch/nn/modules/module.py:1740\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1739\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1740\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/mps-torch/lib/python3.9/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1748\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1750\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1753\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1754\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/mps-torch/lib/python3.9/site-packages/torch/nn/modules/activation.py:1368\u001b[0m, in \u001b[0;36mMultiheadAttention.forward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   1342\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmulti_head_attention_forward(\n\u001b[1;32m   1343\u001b[0m         query,\n\u001b[1;32m   1344\u001b[0m         key,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1365\u001b[0m         is_causal\u001b[38;5;241m=\u001b[39mis_causal,\n\u001b[1;32m   1366\u001b[0m     )\n\u001b[1;32m   1367\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1368\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmulti_head_attention_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1369\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1370\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1371\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1372\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1373\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1374\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1375\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1376\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1377\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_v\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1378\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_zero_attn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1379\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1380\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1381\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1382\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1384\u001b[0m \u001b[43m        \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mneed_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1385\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1386\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage_attn_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage_attn_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1387\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1388\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first \u001b[38;5;129;01mand\u001b[39;00m is_batched:\n\u001b[1;32m   1390\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m attn_output\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m), attn_output_weights\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/mps-torch/lib/python3.9/site-packages/torch/nn/functional.py:6205\u001b[0m, in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   6201\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m use_separate_proj_weight:\n\u001b[1;32m   6202\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m   6203\u001b[0m         in_proj_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   6204\u001b[0m     ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_separate_proj_weight is False but in_proj_weight is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 6205\u001b[0m     q, k, v \u001b[38;5;241m=\u001b[39m \u001b[43m_in_projection_packed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_proj_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_proj_bias\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6206\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6207\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m   6208\u001b[0m         q_proj_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   6209\u001b[0m     ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_separate_proj_weight is True but q_proj_weight is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/mps-torch/lib/python3.9/site-packages/torch/nn/functional.py:5609\u001b[0m, in \u001b[0;36m_in_projection_packed\u001b[0;34m(q, k, v, w, b)\u001b[0m\n\u001b[1;32m   5606\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mis\u001b[39;00m v:\n\u001b[1;32m   5607\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m q \u001b[38;5;129;01mis\u001b[39;00m k:\n\u001b[1;32m   5608\u001b[0m         \u001b[38;5;66;03m# self-attention\u001b[39;00m\n\u001b[0;32m-> 5609\u001b[0m         proj \u001b[38;5;241m=\u001b[39m \u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5610\u001b[0m         \u001b[38;5;66;03m# reshape to 3, E and not E, 3 is deliberate for better memory coalescing and keeping same order as chunk()\u001b[39;00m\n\u001b[1;32m   5611\u001b[0m         proj \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   5612\u001b[0m             proj\u001b[38;5;241m.\u001b[39munflatten(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, (\u001b[38;5;241m3\u001b[39m, E))\n\u001b[1;32m   5613\u001b[0m             \u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5616\u001b[0m             \u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[1;32m   5617\u001b[0m         )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import math\n",
    "# Assuming your vocabulary sizes from the tokenizer\n",
    "input_vocab_size = 10 + 3\n",
    "target_vocab_size = sp.get_piece_size()\n",
    "\n",
    "# Initialize the Transformer model\n",
    "transformer_model = TransformerModel(\n",
    "    input_vocab_size=input_vocab_size,\n",
    "    target_vocab_size=target_vocab_size\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "train_model(transformer_model, dataloader, num_epochs=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 3.1328036260604857\n",
      "Epoch 2/20, Loss: 1.6313927674293518\n",
      "Epoch 3/20, Loss: 1.0483209025859832\n",
      "Epoch 4/20, Loss: 0.825584499835968\n",
      "Epoch 5/20, Loss: 0.7087904393672944\n",
      "Epoch 6/20, Loss: 0.6282270812988281\n",
      "Epoch 7/20, Loss: 0.542253954410553\n",
      "Epoch 8/20, Loss: 0.4829317003488541\n",
      "Epoch 9/20, Loss: 0.41201497554779054\n",
      "Epoch 10/20, Loss: 0.3528533035516739\n",
      "Epoch 11/20, Loss: 0.3169796398282051\n",
      "Epoch 12/20, Loss: 0.2781745755672455\n",
      "Epoch 13/20, Loss: 0.25704569518566134\n",
      "Epoch 14/20, Loss: 0.24458871245384217\n",
      "Epoch 15/20, Loss: 0.20953933715820314\n",
      "Epoch 16/20, Loss: 0.1881439507007599\n",
      "Epoch 17/20, Loss: 0.18920923113822938\n",
      "Epoch 18/20, Loss: 0.16462993681430815\n",
      "Epoch 19/20, Loss: 0.1591998627781868\n",
      "Epoch 20/20, Loss: 0.15676770389080047\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "# Assuming your vocabulary sizes from the tokenizer\n",
    "input_vocab_size = 10 + 3\n",
    "target_vocab_size = sp.get_piece_size()\n",
    "\n",
    "# Initialize the Transformer model\n",
    "transformer_model = TransformerModel(\n",
    "    input_vocab_size=input_vocab_size,\n",
    "    target_vocab_size=target_vocab_size\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "train_model(transformer_model, dataloader, num_epochs=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 2.496651341915131\n",
      "Epoch 2/20, Loss: 0.8746180474758148\n",
      "Epoch 3/20, Loss: 0.666631880402565\n",
      "Epoch 4/20, Loss: 0.5613335084915161\n",
      "Epoch 5/20, Loss: 0.5094714856147766\n",
      "Epoch 6/20, Loss: 0.4561134362220764\n",
      "Epoch 7/20, Loss: 0.35182737052440644\n",
      "Epoch 8/20, Loss: 0.31638810962438585\n",
      "Epoch 9/20, Loss: 0.3067630445957184\n",
      "Epoch 10/20, Loss: 0.2941738975048065\n",
      "Epoch 11/20, Loss: 0.2763662710785866\n",
      "Epoch 12/20, Loss: 0.24181130439043044\n",
      "Epoch 13/20, Loss: 0.2829021456837654\n",
      "Epoch 14/20, Loss: 0.23284145385026933\n",
      "Epoch 15/20, Loss: 0.22157204702496527\n",
      "Epoch 16/20, Loss: 0.19545322686433791\n",
      "Epoch 17/20, Loss: 0.1882915563881397\n",
      "Epoch 18/20, Loss: 0.17262213081121444\n",
      "Epoch 19/20, Loss: 0.18533218607306481\n",
      "Epoch 20/20, Loss: 0.13755528703331948\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "# Assuming your vocabulary sizes from the tokenizer\n",
    "input_vocab_size = 10 + 3\n",
    "target_vocab_size = sp.get_piece_size()\n",
    "\n",
    "# Initialize the Transformer model\n",
    "transformer_model = TransformerModel(\n",
    "    input_vocab_size=input_vocab_size,\n",
    "    target_vocab_size=target_vocab_size\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "train_model(transformer_model, dataloader, num_epochs=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_bos_token_id = 4  # SentencePiece model's tokens\n",
    "target_eos_token_id = 5\n",
    "target_pad_token_id = 3\n",
    "\n",
    "def predict(model, number, tokenizer_num, tokenizer_text, max_length=50):\n",
    "    device = torch.device(\"cpu\")\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        src = torch.tensor([[BOS_TOKEN_ID] + [int(d) for d in str(number)] + [EOS_TOKEN_ID]], dtype=torch.long).to(device)\n",
    "        tgt = torch.tensor([[target_bos_token_id]], dtype=torch.long).to(device)\n",
    "        src_mask = ~torch.ones(src.shape, dtype=torch.bool).to(device)\n",
    "        tgt_mask = ~torch.ones((1, 1), dtype=torch.bool).to(device)\n",
    "        \n",
    "        for _ in range(max_length):\n",
    "            output = model(src, tgt, src_mask, tgt_mask)\n",
    "            next_token = output[:, -1].argmax(dim=-1).unsqueeze(1)\n",
    "            if next_token.item() == target_eos_token_id:\n",
    "                break\n",
    "            tgt = torch.cat([tgt, next_token], dim=1)\n",
    "            tgt_mask = ~torch.ones(tgt.shape, dtype=torch.bool)\n",
    "            \n",
    "        output_tokens = tgt[0][1:].tolist()  # Skip BOS\n",
    "        if target_eos_token_id in output_tokens:\n",
    "            output_tokens = output_tokens[:output_tokens.index(target_eos_token_id)]\n",
    "        return tokenizer_text.decode(output_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'one hundred and twenty'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(transformer_model, 120, tokenize_number_column, sp, max_length=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_accuracy(model, test_df, tokenizer_num, tokenizer_text):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for _, row in test_df.iterrows():\n",
    "        number = row['num']\n",
    "        word = row['word']\n",
    "        predicted_word = predict(model, number, tokenizer_num, tokenizer_text)\n",
    "        print(f\"Number: {number}, Predicted: {predicted_word}, Actual: {word}\")\n",
    "        if predicted_word == word:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number: 1, Predicted: one hundred and eleven, Actual: one\n",
      "Number: 4, Predicted: four hundred and forty-five, Actual: four\n",
      "Number: 13, Predicted: one hundred and thirty-one, Actual: thirteen\n",
      "Number: 14, Predicted: one hundred and forty-six, Actual: fourteen\n",
      "Number: 20, Predicted: two hundred and two, Actual: twenty\n",
      "Number: 21, Predicted: two hundred and twelve, Actual: twenty-one\n",
      "Number: 27, Predicted: two hundred and seventy-two, Actual: twenty-seven\n",
      "Number: 32, Predicted: three hundred and twenty-six, Actual: thirty-two\n",
      "Number: 34, Predicted: three hundred and forty-six, Actual: thirty-four\n",
      "Number: 35, Predicted: three hundred and fifty-five, Actual: thirty-five\n",
      "Number: 40, Predicted: four hundred and four, Actual: forty\n",
      "Number: 47, Predicted: four hundred and seventy-six, Actual: forty-seven\n",
      "Number: 52, Predicted: five hundred and twenty-six, Actual: fifty-two\n",
      "Number: 58, Predicted: five hundred and eighty-six, Actual: fifty-eight\n",
      "Number: 62, Predicted: six hundred and twenty-eight, Actual: sixty-two\n",
      "Number: 64, Predicted: six hundred and forty-six, Actual: sixty-four\n",
      "Number: 71, Predicted: seven hundred and eleven, Actual: seventy-one\n",
      "Number: 80, Predicted: eight hundred and eight, Actual: eighty\n",
      "Number: 85, Predicted: eight hundred and fifty-five, Actual: eighty-five\n",
      "Number: 87, Predicted: eight hundred and seventy-eight, Actual: eighty-seven\n",
      "Number: 91, Predicted: nine hundred and eleven, Actual: ninety-one\n",
      "Number: 95, Predicted: nine hundred and fifty-five, Actual: ninety-five\n",
      "Number: 98, Predicted: nine hundred and eighty-five, Actual: ninety-eight\n",
      "Number: 99, Predicted: nine hundred and ninety-nine, Actual: ninety-nine\n",
      "Number: 102, Predicted: one hundred and two, Actual: one hundred and two\n",
      "Number: 105, Predicted: one hundred and five, Actual: one hundred and five\n",
      "Number: 106, Predicted: one hundred and six, Actual: one hundred and six\n",
      "Number: 121, Predicted: one hundred and twenty-one, Actual: one hundred and twenty-one\n",
      "Number: 128, Predicted: one hundred and twenty-eight, Actual: one hundred and twenty-eight\n",
      "Number: 130, Predicted: one hundred and thirty, Actual: one hundred and thirty\n",
      "Number: 134, Predicted: one hundred and thirty-four, Actual: one hundred and thirty-four\n",
      "Number: 138, Predicted: one hundred and eighty-three, Actual: one hundred and thirty-eight\n",
      "Number: 156, Predicted: one hundred and fifty-six, Actual: one hundred and fifty-six\n",
      "Number: 159, Predicted: one hundred and fifty-nine, Actual: one hundred and fifty-nine\n",
      "Number: 160, Predicted: one hundred and sixty, Actual: one hundred and sixty\n",
      "Number: 161, Predicted: one hundred and sixty-one, Actual: one hundred and sixty-one\n",
      "Number: 166, Predicted: six hundred and eleven, Actual: one hundred and sixty-six\n",
      "Number: 170, Predicted: one hundred and seventy, Actual: one hundred and seventy\n",
      "Number: 187, Predicted: one hundred and eighty-seven, Actual: one hundred and eighty-seven\n",
      "Number: 189, Predicted: one hundred and eighty-nine, Actual: one hundred and eighty-nine\n",
      "Number: 191, Predicted: one hundred and ninety-one, Actual: one hundred and ninety-one\n",
      "Number: 200, Predicted: two hundred and two, Actual: two hundred\n",
      "Number: 201, Predicted: two hundred and one, Actual: two hundred and one\n",
      "Number: 205, Predicted: two hundred and five, Actual: two hundred and five\n",
      "Number: 206, Predicted: two hundred and six, Actual: two hundred and six\n",
      "Number: 214, Predicted: two hundred and forty-one, Actual: two hundred and fourteen\n",
      "Number: 216, Predicted: two hundred and sixteen, Actual: two hundred and sixteen\n",
      "Number: 217, Predicted: two hundred and seventeen, Actual: two hundred and seventeen\n",
      "Number: 230, Predicted: two hundred and thirty, Actual: two hundred and thirty\n",
      "Number: 240, Predicted: two hundred and forty, Actual: two hundred and forty\n",
      "Number: 241, Predicted: two hundred and forty-one, Actual: two hundred and forty-one\n",
      "Number: 242, Predicted: two hundred and forty-two, Actual: two hundred and forty-two\n",
      "Number: 243, Predicted: two hundred and forty-three, Actual: two hundred and forty-three\n",
      "Number: 251, Predicted: two hundred and fifty-one, Actual: two hundred and fifty-one\n",
      "Number: 252, Predicted: two hundred and fifty-two, Actual: two hundred and fifty-two\n",
      "Number: 269, Predicted: two hundred and sixty-nine, Actual: two hundred and sixty-nine\n",
      "Number: 270, Predicted: two hundred and seventy, Actual: two hundred and seventy\n",
      "Number: 273, Predicted: two hundred and seventy-three, Actual: two hundred and seventy-three\n",
      "Number: 276, Predicted: two hundred and seventy-six, Actual: two hundred and seventy-six\n",
      "Number: 288, Predicted: two hundred and eighty-two, Actual: two hundred and eighty-eight\n",
      "Number: 295, Predicted: two hundred and ninety-five, Actual: two hundred and ninety-five\n",
      "Number: 308, Predicted: three hundred and eight, Actual: three hundred and eight\n",
      "Number: 313, Predicted: three hundred and thirteen, Actual: three hundred and thirteen\n",
      "Number: 315, Predicted: three hundred and fifty-one, Actual: three hundred and fifteen\n",
      "Number: 330, Predicted: three hundred and thirty, Actual: three hundred and thirty\n",
      "Number: 337, Predicted: three hundred and thirty-seven, Actual: three hundred and thirty-seven\n",
      "Number: 339, Predicted: three hundred and thirty-nine, Actual: three hundred and thirty-nine\n",
      "Number: 343, Predicted: three hundred and forty-three, Actual: three hundred and forty-three\n",
      "Number: 345, Predicted: three hundred and forty-five, Actual: three hundred and forty-five\n",
      "Number: 366, Predicted: three hundred and sixty-six, Actual: three hundred and sixty-six\n",
      "Number: 372, Predicted: three hundred and seventy-two, Actual: three hundred and seventy-two\n",
      "Number: 378, Predicted: three hundred and seventy-eight, Actual: three hundred and seventy-eight\n",
      "Number: 379, Predicted: three hundred and seventy-nine, Actual: three hundred and seventy-nine\n",
      "Number: 385, Predicted: three hundred and eighty-five, Actual: three hundred and eighty-five\n",
      "Number: 387, Predicted: three hundred and eighty-seven, Actual: three hundred and eighty-seven\n",
      "Number: 389, Predicted: three hundred and eighty-nine, Actual: three hundred and eighty-nine\n",
      "Number: 391, Predicted: three hundred and ninety-one, Actual: three hundred and ninety-one\n",
      "Number: 392, Predicted: three hundred and ninety-two, Actual: three hundred and ninety-two\n",
      "Number: 397, Predicted: three hundred and ninety-seven, Actual: three hundred and ninety-seven\n",
      "Number: 401, Predicted: four hundred and one, Actual: four hundred and one\n",
      "Number: 406, Predicted: four hundred and six, Actual: four hundred and six\n",
      "Number: 413, Predicted: four hundred and thirteen, Actual: four hundred and thirteen\n",
      "Number: 418, Predicted: four hundred and eighty-one, Actual: four hundred and eighteen\n",
      "Number: 427, Predicted: four hundred and twenty-seven, Actual: four hundred and twenty-seven\n",
      "Number: 435, Predicted: four hundred and thirty-five, Actual: four hundred and thirty-five\n",
      "Number: 454, Predicted: four hundred and fifty-four, Actual: four hundred and fifty-four\n",
      "Number: 455, Predicted: four hundred and fifty-five, Actual: four hundred and fifty-five\n",
      "Number: 458, Predicted: four hundred and fifty-eight, Actual: four hundred and fifty-eight\n",
      "Number: 459, Predicted: four hundred and fifty-nine, Actual: four hundred and fifty-nine\n",
      "Number: 460, Predicted: four hundred and sixty, Actual: four hundred and sixty\n",
      "Number: 461, Predicted: four hundred and sixty-one, Actual: four hundred and sixty-one\n",
      "Number: 466, Predicted: six hundred and forty-five, Actual: four hundred and sixty-six\n",
      "Number: 471, Predicted: four hundred and seventy-one, Actual: four hundred and seventy-one\n",
      "Number: 474, Predicted: four hundred and seventy-four, Actual: four hundred and seventy-four\n",
      "Number: 475, Predicted: four hundred and seventy-five, Actual: four hundred and seventy-five\n",
      "Number: 476, Predicted: four hundred and seventy-six, Actual: four hundred and seventy-six\n",
      "Number: 484, Predicted: four hundred and eighty-six, Actual: four hundred and eighty-four\n",
      "Number: 489, Predicted: four hundred and eighty-nine, Actual: four hundred and eighty-nine\n",
      "Number: 491, Predicted: four hundred and ninety-one, Actual: four hundred and ninety-one\n",
      "Number: 492, Predicted: four hundred and twenty-nine, Actual: four hundred and ninety-two\n",
      "Number: 498, Predicted: four hundred and ninety-eight, Actual: four hundred and ninety-eight\n",
      "Number: 502, Predicted: five hundred and two, Actual: five hundred and two\n",
      "Number: 504, Predicted: five hundred and four, Actual: five hundred and four\n",
      "Number: 508, Predicted: five hundred and eight, Actual: five hundred and eight\n",
      "Number: 510, Predicted: five hundred and one, Actual: five hundred and ten\n",
      "Number: 520, Predicted: five hundred and twenty, Actual: five hundred and twenty\n",
      "Number: 524, Predicted: five hundred and twenty-four, Actual: five hundred and twenty-four\n",
      "Number: 540, Predicted: five hundred and forty, Actual: five hundred and forty\n",
      "Number: 546, Predicted: five hundred and forty-six, Actual: five hundred and forty-six\n",
      "Number: 553, Predicted: five hundred and fifty-three, Actual: five hundred and fifty-three\n",
      "Number: 555, Predicted: five hundred and fifty-six, Actual: five hundred and fifty-five\n",
      "Number: 556, Predicted: five hundred and fifty-six, Actual: five hundred and fifty-six\n",
      "Number: 560, Predicted: five hundred and sixty, Actual: five hundred and sixty\n",
      "Number: 561, Predicted: five hundred and sixty-one, Actual: five hundred and sixty-one\n",
      "Number: 562, Predicted: five hundred and sixty-two, Actual: five hundred and sixty-two\n",
      "Number: 563, Predicted: five hundred and sixty-three, Actual: five hundred and sixty-three\n",
      "Number: 564, Predicted: five hundred and sixty-four, Actual: five hundred and sixty-four\n",
      "Number: 565, Predicted: five hundred and sixty-five, Actual: five hundred and sixty-five\n",
      "Number: 566, Predicted: five hundred and sixty-six, Actual: five hundred and sixty-six\n",
      "Number: 573, Predicted: five hundred and seventy-three, Actual: five hundred and seventy-three\n",
      "Number: 574, Predicted: five hundred and seventy-four, Actual: five hundred and seventy-four\n",
      "Number: 577, Predicted: five hundred and seventy-seven, Actual: five hundred and seventy-seven\n",
      "Number: 592, Predicted: five hundred and ninety-two, Actual: five hundred and ninety-two\n",
      "Number: 600, Predicted: six hundred and eight, Actual: six hundred\n",
      "Number: 612, Predicted: six hundred and twelve, Actual: six hundred and twelve\n",
      "Number: 614, Predicted: six hundred and fourteen, Actual: six hundred and fourteen\n",
      "Number: 642, Predicted: six hundred and forty-two, Actual: six hundred and forty-two\n",
      "Number: 646, Predicted: six hundred and forty-six, Actual: six hundred and forty-six\n",
      "Number: 647, Predicted: six hundred and forty-seven, Actual: six hundred and forty-seven\n",
      "Number: 654, Predicted: six hundred and fifty-four, Actual: six hundred and fifty-four\n",
      "Number: 661, Predicted: six hundred and sixty-one, Actual: six hundred and sixty-one\n",
      "Number: 663, Predicted: six hundred and thirty-six, Actual: six hundred and sixty-three\n",
      "Number: 674, Predicted: six hundred and seventy-four, Actual: six hundred and seventy-four\n",
      "Number: 681, Predicted: six hundred and eighty-one, Actual: six hundred and eighty-one\n",
      "Number: 683, Predicted: six hundred and eighty-three, Actual: six hundred and eighty-three\n",
      "Number: 686, Predicted: six hundred and eighty-six, Actual: six hundred and eighty-six\n",
      "Number: 690, Predicted: six hundred and ninety, Actual: six hundred and ninety\n",
      "Number: 698, Predicted: six hundred and eighty-nine, Actual: six hundred and ninety-eight\n",
      "Number: 699, Predicted: six hundred and ninety-six, Actual: six hundred and ninety-nine\n",
      "Number: 700, Predicted: seven hundred, Actual: seven hundred\n",
      "Number: 701, Predicted: seven hundred and one, Actual: seven hundred and one\n",
      "Number: 702, Predicted: seven hundred and two, Actual: seven hundred and two\n",
      "Number: 719, Predicted: seven hundred and nineteen, Actual: seven hundred and nineteen\n",
      "Number: 724, Predicted: seven hundred and twenty-four, Actual: seven hundred and twenty-four\n",
      "Number: 725, Predicted: seven hundred and twenty-five, Actual: seven hundred and twenty-five\n",
      "Number: 726, Predicted: seven hundred and twenty-six, Actual: seven hundred and twenty-six\n",
      "Number: 727, Predicted: seven hundred and twenty-seven, Actual: seven hundred and twenty-seven\n",
      "Number: 729, Predicted: seven hundred and twenty-nine, Actual: seven hundred and twenty-nine\n",
      "Number: 733, Predicted: seven hundred and thirty-three, Actual: seven hundred and thirty-three\n",
      "Number: 738, Predicted: seven hundred and eighty-three, Actual: seven hundred and thirty-eight\n",
      "Number: 742, Predicted: seven hundred and forty-two, Actual: seven hundred and forty-two\n",
      "Number: 747, Predicted: seven hundred and forty-seven, Actual: seven hundred and forty-seven\n",
      "Number: 748, Predicted: seven hundred and forty-eight, Actual: seven hundred and forty-eight\n",
      "Number: 763, Predicted: seven hundred and sixty-three, Actual: seven hundred and sixty-three\n",
      "Number: 766, Predicted: six hundred and seventy-seven, Actual: seven hundred and sixty-six\n",
      "Number: 768, Predicted: seven hundred and sixty-eight, Actual: seven hundred and sixty-eight\n",
      "Number: 769, Predicted: seven hundred and sixty-nine, Actual: seven hundred and sixty-nine\n",
      "Number: 771, Predicted: seven hundred and seventy-one, Actual: seven hundred and seventy-one\n",
      "Number: 772, Predicted: seven hundred and twenty-seven, Actual: seven hundred and seventy-two\n",
      "Number: 775, Predicted: seven hundred and fifty-seven, Actual: seven hundred and seventy-five\n",
      "Number: 776, Predicted: seven hundred and sixty-seven, Actual: seven hundred and seventy-six\n",
      "Number: 779, Predicted: seven hundred and seventy-nine, Actual: seven hundred and seventy-nine\n",
      "Number: 782, Predicted: seven hundred and eighty-two, Actual: seven hundred and eighty-two\n",
      "Number: 791, Predicted: seven hundred and ninety-one, Actual: seven hundred and ninety-one\n",
      "Number: 794, Predicted: seven hundred and ninety-four, Actual: seven hundred and ninety-four\n",
      "Number: 795, Predicted: seven hundred and ninety-five, Actual: seven hundred and ninety-five\n",
      "Number: 804, Predicted: eight hundred and four, Actual: eight hundred and four\n",
      "Number: 805, Predicted: eight hundred and five, Actual: eight hundred and five\n",
      "Number: 812, Predicted: eight hundred and twenty-one, Actual: eight hundred and twelve\n",
      "Number: 815, Predicted: eight hundred and fifty-one, Actual: eight hundred and fifteen\n",
      "Number: 818, Predicted: eight hundred and eighty-one, Actual: eight hundred and eighteen\n",
      "Number: 821, Predicted: eight hundred and twenty-one, Actual: eight hundred and twenty-one\n",
      "Number: 831, Predicted: eight hundred and thirty-one, Actual: eight hundred and thirty-one\n",
      "Number: 838, Predicted: eight hundred and thirty-five, Actual: eight hundred and thirty-eight\n",
      "Number: 839, Predicted: eight hundred and thirty-nine, Actual: eight hundred and thirty-nine\n",
      "Number: 840, Predicted: eight hundred and forty, Actual: eight hundred and forty\n",
      "Number: 847, Predicted: eight hundred and forty-seven, Actual: eight hundred and forty-seven\n",
      "Number: 848, Predicted: eight hundred and forty-two, Actual: eight hundred and forty-eight\n",
      "Number: 856, Predicted: eight hundred and fifty-six, Actual: eight hundred and fifty-six\n",
      "Number: 857, Predicted: eight hundred and fifty-seven, Actual: eight hundred and fifty-seven\n",
      "Number: 860, Predicted: eight hundred and sixty, Actual: eight hundred and sixty\n",
      "Number: 862, Predicted: eight hundred and sixty-two, Actual: eight hundred and sixty-two\n",
      "Number: 871, Predicted: eight hundred and seventy-one, Actual: eight hundred and seventy-one\n",
      "Number: 875, Predicted: eight hundred and fifty-seven, Actual: eight hundred and seventy-five\n",
      "Number: 878, Predicted: eight hundred and seventy-eight, Actual: eight hundred and seventy-eight\n",
      "Number: 880, Predicted: eight hundred and eighty, Actual: eight hundred and eighty\n",
      "Number: 888, Predicted: eight hundred and eighty-five, Actual: eight hundred and eighty-eight\n",
      "Number: 890, Predicted: eight hundred and ninety, Actual: eight hundred and ninety\n",
      "Number: 897, Predicted: eight hundred and ninety-seven, Actual: eight hundred and ninety-seven\n",
      "Number: 929, Predicted: nine hundred and twenty-nine, Actual: nine hundred and twenty-nine\n",
      "Number: 937, Predicted: nine hundred and thirty-seven, Actual: nine hundred and thirty-seven\n",
      "Number: 944, Predicted: nine hundred and forty-four, Actual: nine hundred and forty-four\n",
      "Number: 955, Predicted: five hundred and ninety-five, Actual: nine hundred and fifty-five\n",
      "Number: 957, Predicted: nine hundred and fifty-seven, Actual: nine hundred and fifty-seven\n",
      "Number: 962, Predicted: nine hundred and sixty-two, Actual: nine hundred and sixty-two\n",
      "Number: 976, Predicted: nine hundred and seventy-six, Actual: nine hundred and seventy-six\n",
      "Number: 980, Predicted: nine hundred and eighty, Actual: nine hundred and eighty\n",
      "Number: 982, Predicted: nine hundred and eighty-two, Actual: nine hundred and eighty-two\n",
      "Number: 992, Predicted: nine hundred and ninety-two, Actual: nine hundred and ninety-two\n",
      "Number: 996, Predicted: nine hundred and sixty-nine, Actual: nine hundred and ninety-six\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.73"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy(transformer_model, val_df, tokenize_number_column, sp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number: 521, Predicted: five hundred and twenty-one, Actual: five hundred and twenty-one\n",
      "Number: 737, Predicted: seven hundred and thirty-eight, Actual: seven hundred and thirty-seven\n",
      "Number: 740, Predicted: seven hundred and forty, Actual: seven hundred and forty\n",
      "Number: 660, Predicted: six hundred and sixty, Actual: six hundred and sixty\n",
      "Number: 411, Predicted: four hundred and eleven, Actual: four hundred and eleven\n",
      "Number: 678, Predicted: six hundred and eighty-seven, Actual: six hundred and seventy-eight\n",
      "Number: 626, Predicted: six hundred and twenty-six, Actual: six hundred and twenty-six\n",
      "Number: 513, Predicted: five hundred and thirteen, Actual: five hundred and thirteen\n",
      "Number: 859, Predicted: eight hundred and fifty-nine, Actual: eight hundred and fifty-nine\n",
      "Number: 136, Predicted: one hundred and thirty-six, Actual: one hundred and thirty-six\n",
      "Number: 811, Predicted: eight hundred and eleven, Actual: eight hundred and eleven\n",
      "Number: 76, Predicted: seven hundred and sixty-three, Actual: seventy-six\n",
      "Number: 636, Predicted: six hundred and thirty-six, Actual: six hundred and thirty-six\n",
      "Number: 973, Predicted: nine hundred and seventy-three, Actual: nine hundred and seventy-three\n",
      "Number: 938, Predicted: nine hundred and thirty-eight, Actual: nine hundred and thirty-eight\n",
      "Number: 899, Predicted: eight hundred and ninety-eight, Actual: eight hundred and ninety-nine\n",
      "Number: 280, Predicted: two hundred and eighty, Actual: two hundred and eighty\n",
      "Number: 883, Predicted: eight hundred and thirty-eight, Actual: eight hundred and eighty-three\n",
      "Number: 761, Predicted: six hundred and seventy-one, Actual: seven hundred and sixty-one\n",
      "Number: 319, Predicted: three hundred and nineteen, Actual: three hundred and nineteen\n",
      "Number: 549, Predicted: five hundred and forty-nine, Actual: five hundred and forty-nine\n",
      "Number: 174, Predicted: one hundred and seventy-four, Actual: one hundred and seventy-four\n",
      "Number: 371, Predicted: three hundred and seventeen, Actual: three hundred and seventy-one\n",
      "Number: 527, Predicted: five hundred and twenty-seven, Actual: five hundred and twenty-seven\n",
      "Number: 210, Predicted: two hundred and ten, Actual: two hundred and ten\n",
      "Number: 235, Predicted: two hundred and thirty-five, Actual: two hundred and thirty-five\n",
      "Number: 101, Predicted: one hundred and one, Actual: one hundred and one\n",
      "Number: 986, Predicted: nine hundred and eighty-six, Actual: nine hundred and eighty-six\n",
      "Number: 902, Predicted: nine hundred and two, Actual: nine hundred and two\n",
      "Number: 947, Predicted: nine hundred and forty-seven, Actual: nine hundred and forty-seven\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7666666666666667"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy(transformer_model, train_df[:30], tokenize_number_column, sp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mps-torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
